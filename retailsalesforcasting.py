# -*- coding: utf-8 -*-
"""RetailSalesForcasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S53ncVda6U9cYPhu5qd-hVVvQHxgeJAH
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import plotly.io as pio
from sklearn.metrics import mean_squared_error, mean_absolute_error
from prophet import Prophet
from pandas.tseries.holiday import USFederalHolidayCalendar as calendar
from sklearn.model_selection import GridSearchCV
import matplotlib.dates as mdates
from sklearn.model_selection import ParameterGrid
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense,Dropout
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tensorflow.keras.optimizers import Adam
import itertools
import warnings
warnings.filterwarnings('ignore')
plt.style.use('ggplot')
plt.style.use('fivethirtyeight')

def mean_absolute_percentage_error(y_true, y_pred):
    """Calculates MAPE given y_true and y_pred"""
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

# Upload Kaggle API Key
from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download anirudhchauhan/retail-store-inventory-forecasting-dataset

# Unzip Dataset
!unzip retail-store-inventory-forecasting-dataset.zip

# Load Data
data_sales=pd.read_csv('/content/retail_store_inventory.csv')

data_sales.head(10)

data_sales.info()

data_sales.shape

# Convert Categorical Columns
data_sales[['Region','Category','Seasonality','Weather Condition']]=data_sales[['Region','Category','Seasonality','Weather Condition']].astype('category')

"""# **Cleaning and Preprocessing**"""

data_sales.info()

# Boxplots the distribution of 'Units Sold' by Region
sns.boxplot(data=data_sales,x='Region',y='Units Sold')
plt.show()

# Boxplots the distribution of 'Units Ordered' by Region
sns.boxplot(data=data_sales,x='Region',y='Units Ordered')
plt.show()

sns.boxplot(data=data_sales,x='Category',y='Demand Forecast')
plt.show()

# Check for Missing Values
data_sales.isnull().sum()

# Descriptive Statistics
data_sales.describe()

# Correlation Analysis
corrlation=data_sales.copy()
corrlation.drop(columns=['Date','Store ID','Product ID'],inplace=True)

for col in ['Region','Category','Seasonality','Weather Condition']:
    corrlation[col]=corrlation[col].astype('category').cat.codes

corrlation.corr()

"""# **Visualistaion**"""

plt.figure(figsize=(10, 6))
sns.heatmap(corrlation.corr(),annot=True,cmap='coolwarm',linewidths=0.5, fmt='.2f')
plt.title('Correlation Heatmap')
plt.show()

# Convert 'Date' column to datetime format
data_sales['Date'] = pd.to_datetime(data_sales['Date'])

# Now filter the correct date range
filtered_data = data_sales[(data_sales['Date'] >= '2022-01-01') & (data_sales['Date'] <= '2022-12-31')]

plt.figure(figsize=(12, 6))
sns.lineplot(data=filtered_data, x='Date', y='Demand Forecast')

plt.title('Demand Forecast Over Time (2022)')
plt.xlabel('Date')
plt.ylabel('Demand Forecast')

import matplotlib.dates as mdates

plt.gca().xaxis.set_major_locator(mdates.MonthLocator())  # Show one label per month
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))  # Format as "Jan 2022"

plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))
sns.histplot(data=data_sales, x='Demand Forecast', bins=30, kde=True)
plt.title('Distribution of Demand Forecast')
plt.xlabel('Demand Forecast')
plt.ylabel('Frequency')
plt.show()

# Extract day of the week from the Date column
data_sales['DayOfWeek'] = pd.to_datetime(data_sales['Date']).dt.day_name()

# Group by day of the week and sum the uDemand Forecast
daily_sales = data_sales.groupby('DayOfWeek')['Demand Forecast'].sum().reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])

# Plot the data
plt.figure(figsize=(12, 6))
daily_sales.plot(kind='line', marker='o')
plt.title('Total Demand Forecast by Day of the Week')
plt.xlabel('Day of the Week')
plt.ylabel('Total Demand Forecast')
plt.grid(True)
plt.show()

data_sales['Month'] = pd.to_datetime(data_sales['Date']).dt.month
plt.figure(figsize=(12, 6))
sns.lineplot(data=data_sales, x='Month', y='Demand Forecast', estimator=sum, ci=None)
plt.title('Total Demand Forecast by Month')
plt.xlabel('Month')
plt.ylabel('Total Demand Forecast')
plt.show()

plt.figure(figsize=(12, 6))
sns.histplot(data=data_sales, x='Price', bins=30, kde=True)
plt.title('Distribution of Price')
plt.xlabel('Price')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(20, 10))
sns.lineplot(data=data_sales, x='Date', y='Demand Forecast', hue='Region', estimator=sum, ci=None)

plt.title('Total Demand Forecast by Region Over Time')
plt.xlabel('Date')
plt.ylabel('Total Demand Forecast')

# Fix the X-axis formatting
plt.gca().xaxis.set_major_locator(mdates.MonthLocator())  # Show one label per month
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))  # Format as "Jan 2022"

plt.xticks(rotation=45)  # Rotate labels for readability
plt.tight_layout()  # Adjust layout to prevent cutoff
plt.show()

plt.pie(data_sales['Region'].value_counts(), labels=data_sales['Region'].value_counts().index, autopct='%1.1f%%')
plt.title('Distribution of Regions')
plt.show()

plt.pie(data_sales['Category'].value_counts(), labels=data_sales['Category'].value_counts().index, autopct='%1.1f%%')
plt.title('Distribution of Categories')
plt.show()

plt.pie(data_sales['Seasonality'].value_counts(), labels=data_sales['Seasonality'].value_counts().index, autopct='%1.1f%%')
plt.title('Distribution of Seasonality')
plt.show()

"""# **Understanding Trends**"""

grouped_data_weather = data_sales.groupby(['Category', 'Weather Condition'])['Demand Forecast'].sum().reset_index()

fig=px.bar(grouped_data_weather,x='Category',y='Demand Forecast',color='Weather Condition',color_discrete_map={  # Assign specific colors
        'Rainy': 'blue',
        'Sunny': 'orange',
        'Cloudy': 'grey',
        'Snowy': 'lightblue'
    })
fig.show()

grouped_data_area = data_sales.groupby(['Date', 'Region'])['Demand Forecast'].sum().reset_index()
px.area(grouped_data_area,x='Date',y='Demand Forecast',color='Region')

grouped_data_region = data_sales.groupby(['Category', 'Region'])['Demand Forecast'].sum().reset_index()
px.bar(grouped_data_region,x='Category',y='Demand Forecast',color='Region',barmode='group')

grouped_data_seasonality = data_sales.groupby(['Category', 'Seasonality'])['Demand Forecast'].sum().reset_index()
px.bar(grouped_data_seasonality,x='Category',y='Demand Forecast',color='Seasonality',barmode='group')

pip install prophet

"""# **Feature Engineering**"""

data_sales['Date'].min(),data_sales['Date'].max()

# Step 1: Prepare Prophet Data
daily_df = data_sales.copy()
daily_df['Date'] = pd.to_datetime(daily_df['Date'])

# Group by day: total demand per date
daily_df = daily_df.groupby('Date', as_index=False)['Units Sold'].sum()

# Add engineered features
daily_df['day_of_week'] = daily_df['Date'].dt.dayofweek
daily_df['month'] = daily_df['Date'].dt.month
daily_df['is_weekend'] = daily_df['day_of_week'].isin([5, 6]).astype(int)

# Rename for Prophet
daily_df = daily_df.rename(columns={'Date': 'ds', 'Units Sold': 'y'})

daily_df.shape

# Step 2: spliting by date
split_date = '2023-10-01'
train_df = daily_df[daily_df['ds'] < split_date]
test_df = daily_df[daily_df['ds'] >= split_date]

test_df.shape,train_df.shape

"""# **Modeling and Trends**

Prophet
"""

# Step 3: Prophet Model with Regressors
m = Prophet()
m.add_regressor('day_of_week')
m.add_regressor('month')
m.add_regressor('is_weekend')

# Train the model
m.fit(train_df[['ds', 'y', 'day_of_week', 'month', 'is_weekend']])

# Step 4: Create future dataframe and forecast
future = m.make_future_dataframe(periods=len(test_df), freq='D')
future['day_of_week'] = future['ds'].dt.dayofweek
future['month'] = future['ds'].dt.month
future['is_weekend'] = future['day_of_week'].isin([5, 6]).astype(int)

forecast = m.predict(future)

# Step 5: Evaluation
forecast_test = forecast[forecast['ds'].isin(test_df['ds'])]
y_true = test_df['y'].values
y_pred = forecast_test['yhat'].values

rmse = np.sqrt(mean_squared_error(y_true, y_pred))
mae = mean_absolute_error(y_true, y_pred)
mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

print(f"RMSE: {rmse:.2f}")
print(f"MAE: {mae:.2f}")
print(f"MAPE: {mape:.2f}%")

residuals_prophet_baseline = y_true - y_pred
plt.figure(figsize=(12, 4))
plt.plot(test_df['ds'], residuals_prophet_baseline, label='Prophet Residuals', color='green', marker='o', linestyle='None')
plt.axhline(0, color='red', linestyle='--')
plt.title('Baseline Prophet Residuals Over Time')
plt.xlabel('Date')
plt.ylabel('Residual (Actual - Forecast)')
plt.legend()
plt.show()

plt.figure(figsize=(8, 5))
sns.histplot(residuals_prophet_baseline, kde=True)
plt.title('Distribution of Baseline Prophet Residuals')
plt.xlabel('Residual')
plt.show()

"""LSTM"""

train_data_lstm = train_df['y'].values
test_data_lstm = test_df['y'].values

# past 14 days to predict next day
SEQ_LEN = 14

def create_sequences(data, seq_length):
    """Creates sequences and labels for LSTM."""
    xs, ys = [], []
    for i in range(len(data) - seq_length):
        x = data[i:(i + seq_length)]
        y = data[i + seq_length]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

X_train, y_train = create_sequences(train_data_lstm, SEQ_LEN)
X_test, y_test = create_sequences(test_data_lstm, SEQ_LEN)

X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Build BASELINE LSTM Model
model_lstm = Sequential()
model_lstm.add(LSTM(64, activation='relu', input_shape=(SEQ_LEN, 1)))
model_lstm.add(Dense(1))

model_lstm.compile(optimizer='adam', loss='mse')

print("Training baseline LSTM...")
history_lstm_baseline = model_lstm.fit(X_train, y_train,
                                                epochs=30,
                                                batch_size=32,
                                                validation_data=(X_test, y_test),
                                                verbose=0)

# Predict on Test Set
y_pred_lstm = model_lstm.predict(X_test).flatten()

# Evaluate
rmse_lstm = np.sqrt(mean_squared_error(y_test, y_pred_lstm))
mae_lstm = mean_absolute_error(y_test, y_pred_lstm)
mape_lstm = mean_absolute_percentage_error(y_test, y_pred_lstm)

print("\n--- Baseline LSTM Model ---")
print(f"LSTM RMSE: {rmse_lstm:.2f}")
print(f"LSTM MAE: {mae_lstm:.2f}")
print(f"LSTM MAPE: {mape_lstm:.2f}%")

test_dates_for_lstm_eval = test_df['ds'].iloc[SEQ_LEN:]

residuals_lstm = y_test - y_pred_lstm
plt.figure(figsize=(12, 4))
plt.plot(test_dates_for_lstm_eval, residuals_lstm, label='LSTM Residuals', color='purple', marker='.', linestyle='None')
plt.axhline(0, color='red', linestyle='--')
plt.title('Baseline LSTM Residuals Over Time')
plt.xlabel('Date')
plt.ylabel('Residual (Actual - Forecast)')
plt.legend()
plt.show()

plt.figure(figsize=(8, 5))
sns.histplot(residuals_lstm, kde=True, color='purple')
plt.title('Distribution of Baseline LSTM Residuals')
plt.xlabel('Residual')
plt.show()

"""# **Train Models With Holidays**

Prophet
"""

cal = calendar()
holidays_list = cal.holidays(start=daily_df['ds'].min(),
                             end=daily_df['ds'].max(),
                             return_name=True)
holiday_df = pd.DataFrame(data=holidays_list, columns=['holiday'])
holiday_df = holiday_df.reset_index().rename(columns={'index': 'ds'})
holiday_df['ds'] = pd.to_datetime(holiday_df['ds'])

holiday_df.head()

m_hols = Prophet(holidays=holiday_df)

m_hols.add_regressor('day_of_week')
m_hols.add_regressor('month')
m_hols.add_regressor('is_weekend')

# Train the model using the training data
m_hols.fit(train_df[['ds', 'y', 'day_of_week', 'month', 'is_weekend']])

# Create future dataframe for prediction
future_hols = m_hols.make_future_dataframe(periods=len(test_df), freq='D')
# Add regressor values to the future dataframe
future_hols['day_of_week'] = future_hols['ds'].dt.dayofweek
future_hols['month'] = future_hols['ds'].dt.month
future_hols['is_weekend'] = future_hols['day_of_week'].isin([5, 6]).astype(int)

# Make predictions
forecast_hols = m_hols.predict(future_hols)

# Evaluate on the test set
forecast_test_hols = forecast_hols[forecast_hols['ds'].isin(test_df['ds'])]
y_true_hols = test_df['y'].values
y_pred_hols = forecast_test_hols['yhat'].values

# Calculate Metrics
rmse_hols = np.sqrt(mean_squared_error(y_true_hols, y_pred_hols))
mae_hols = mean_absolute_error(y_true_hols, y_pred_hols)
mape_hols = mean_absolute_percentage_error(y_true_hols, y_pred_hols)


print("\n--- Prophet Model with Holidays ---")
print(f"RMSE: {rmse_hols:.2f}")
print(f"MAE: {mae_hols:.2f}")
print(f"MAPE: {mape_hols:.2f}%")

"""LSTM"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Create daily_df with the aggregated holiday/promotion flag
daily_df_features = data_sales.groupby('Date', as_index=False).agg(
    y=('Units Sold', 'sum'),
    holiday_promo_flag=('Holiday/Promotion', 'max')  # 1 if any promo on that day, else 0
)

# Convert 'Date' to datetime and add other time features
daily_df_features['ds'] = pd.to_datetime(daily_df_features['Date'])
daily_df_features['day_of_week'] = daily_df_features['ds'].dt.dayofweek
daily_df_features['month'] = daily_df_features['ds'].dt.month
daily_df_features['is_weekend'] = daily_df_features['day_of_week'].isin([5, 6]).astype(int)

# Ensure 'ds' is kept for splitting, then drop before scaling if not used as feature
daily_df_for_lstm = daily_df_features[['ds', 'y', 'day_of_week', 'month', 'is_weekend', 'holiday_promo_flag']].copy()

# Features to use for LSTM input
# 'y' is the target, but also used as a feature (past sales)
lstm_feature_columns = ['y', 'day_of_week', 'month', 'is_weekend', 'holiday_promo_flag']
data_to_scale = daily_df_for_lstm[lstm_feature_columns].values

# Scale all selected features
scaler_features = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler_features.fit_transform(data_to_scale)

# We need a separate scaler for the 'y' column to inverse_transform predictions
scaler_y_only = MinMaxScaler(feature_range=(0, 1))
# Fit on the 'y' column (which is the first column of data_to_scale)
scaled_y_target = data_to_scale[:,0].reshape(-1, 1) # Reshape for scaler
scaler_y_only.fit(scaled_y_target)


# Split scaled data based on the original split_date
# Find the index corresponding to the split_date in daily_df_for_lstm
split_date_str = '2023-10-01' # Your split date
split_idx = daily_df_for_lstm[daily_df_for_lstm['ds'] >= pd.to_datetime(split_date_str)].index[0]

train_scaled_lstm = scaled_data[:split_idx]
test_scaled_lstm = scaled_data[split_idx:]

print(f"Shape of train_scaled_lstm: {train_scaled_lstm.shape}")
print(f"Shape of test_scaled_lstm: {test_scaled_lstm.shape}")

SEQ_LEN = 14
N_FEATURES = len(lstm_feature_columns)

def create_sequences_multi(data, seq_length, n_features):
    xs, ys = [], []
    for i in range(len(data) - seq_length):
        x = data[i:(i + seq_length), :]
        y = data[i + seq_length, 0]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

X_train_lstm_hols, y_train_lstm_hols = create_sequences_multi(train_scaled_lstm, SEQ_LEN, N_FEATURES)
X_test_lstm_hols, y_test_lstm_hols = create_sequences_multi(test_scaled_lstm, SEQ_LEN, N_FEATURES)

print(f"X_train_lstm_hols shape: {X_train_lstm_hols.shape}")
print(f"y_train_lstm_hols shape: {y_train_lstm_hols.shape}")
print(f"X_test_lstm_hols shape: {X_test_lstm_hols.shape}")
print(f"y_test_lstm_hols shape: {y_test_lstm_hols.shape}")

# Build LSTM Model
model_lstm_hols = Sequential()
model_lstm_hols.add(LSTM(64, activation='relu', input_shape=(SEQ_LEN, N_FEATURES))) # 64 units, same as baseline
model_lstm_hols.add(Dense(1)) # Output is a single value (the next 'y')

model_lstm_hols.compile(optimizer='adam', loss='mse')

print("\nTraining LSTM with holiday/promotion feature...")
history_lstm_hols = model_lstm_hols.fit(X_train_lstm_hols, y_train_lstm_hols,
                                          epochs=30,
                                          batch_size=32,
                                          validation_data=(X_test_lstm_hols, y_test_lstm_hols),
                                          verbose=0)
print("LSTM with holiday/promotion feature training complete.")

# Predict on Test Set (predictions are scaled)
y_pred_scaled_lstm_hols = model_lstm_hols.predict(X_test_lstm_hols)

# Inverse transform predictions to original 'y' scale
y_pred_lstm_hols_unscaled = scaler_y_only.inverse_transform(y_pred_scaled_lstm_hols).flatten()

# Get the corresponding TRUE 'y' values in original scale for evaluation
# y_test_lstm_hols are scaled. We need the original unscaled 'y' values.
# These correspond to the 'y' column starting from split_idx + SEQ_LEN
y_true_lstm_hols_unscaled = daily_df_for_lstm['y'].iloc[split_idx + SEQ_LEN:].values


# Evaluate using original scale values
rmse_lstm_hols = np.sqrt(mean_squared_error(y_true_lstm_hols_unscaled, y_pred_lstm_hols_unscaled))
mae_lstm_hols = mean_absolute_error(y_true_lstm_hols_unscaled, y_pred_lstm_hols_unscaled)
mape_lstm_hols = mean_absolute_percentage_error(y_true_lstm_hols_unscaled, y_pred_lstm_hols_unscaled)

print("\n--- LSTM Model with 'Holiday/Promotion' Feature (Baseline parameters) ---")
print(f"LSTM Holiday/Promo RMSE: {rmse_lstm_hols:.2f}")
print(f"LSTM Holiday/Promo MAE: {mae_lstm_hols:.2f}")
print(f"LSTM Holiday/Promo MAPE: {mape_lstm_hols:.2f}%")

"""# **Models With Hyperparameters**

Prophet
"""

import logging
prophet_logger = logging.getLogger("prophet")
prophet_logger.setLevel(logging.WARNING)
cmdstanpy_logger = logging.getLogger("cmdstanpy")
cmdstanpy_logger.setLevel(logging.WARNING)

# Define the parameter grid
param_grid_prophet = {
    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],
    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],
    'holidays_prior_scale': [0.01, 0.1, 1.0, 10.0]
}

best_rmse_prophet = float('inf')
best_mae_prophet = float('inf')
best_mape_prophet = float('inf')
best_params_prophet = {}

for params in ParameterGrid(param_grid_prophet):
    print(f"Testing Prophet with params: {params}")
    model_gs = Prophet(**params, holidays=holiday_df)
    model_gs.add_regressor('day_of_week')
    model_gs.add_regressor('month')
    model_gs.add_regressor('is_weekend')

    # Fit on training data
    model_gs.fit(train_df[['ds', 'y', 'day_of_week', 'month', 'is_weekend']])

    # Prepare future dataframe for prediction
    future_gs = model_gs.make_future_dataframe(periods=len(test_df), freq='D')
    future_gs['day_of_week'] = future_gs['ds'].dt.dayofweek
    future_gs['month'] = future_gs['ds'].dt.month
    future_gs['is_weekend'] = future_gs['day_of_week'].isin([5, 6]).astype(int)

    # Predict
    forecast_gs = model_gs.predict(future_gs)
    forecast_test_gs = forecast_gs[forecast_gs['ds'].isin(test_df['ds'])]
    y_pred_gs = forecast_test_gs['yhat'].values

    # Calculate metrics for current params
    current_rmse = np.sqrt(mean_squared_error(y_true, y_pred_gs))
    current_mae = mean_absolute_error(y_true, y_pred_gs)
    current_mape = mean_absolute_percentage_error(y_true, y_pred_gs)

    if current_rmse < best_rmse_prophet:
        best_rmse_prophet = current_rmse
        best_mae_prophet = current_mae
        best_mape_prophet = current_mape
        best_params_prophet = params
        print(f"    New best RMSE: {best_rmse_prophet:.2f} (MAE: {best_mae_prophet:.2f}, MAPE: {best_mape_prophet:.2f}%) with params: {best_params_prophet}")

print("\nProphet Hyperparameter Tuning Complete.")
print(f"Best hyperparameters: {best_params_prophet}")
print(f"Best RMSE from tuning: {best_rmse_prophet:.2f}")
print(f"Corresponding MAE: {best_mae_prophet:.2f}")
print(f"Corresponding MAPE: {best_mape_prophet:.2f}%")


# --- Question: Why is he training again with best hp after finding the best hp? ---
# Answer below. The refitting step is good practice.

# Refit with best params (Good Practice)
print("\nRefitting final Prophet model with best hyperparameters...")
final_best_prophet_model = Prophet(**best_params_prophet, holidays=holiday_df)
final_best_prophet_model.add_regressor('day_of_week')
final_best_prophet_model.add_regressor('month')
final_best_prophet_model.add_regressor('is_weekend')

# Fit the final model on the training data
final_best_prophet_model.fit(train_df[['ds', 'y', 'day_of_week', 'month', 'is_weekend']])

print(f"Using best parameters: {best_params_prophet}")

final_best_prophet_model = Prophet(**best_params_prophet, holidays=holiday_df)
final_best_prophet_model.add_regressor('day_of_week')
final_best_prophet_model.add_regressor('month')
final_best_prophet_model.add_regressor('is_weekend')

# Fit the final model on the training data
print("Fitting model on train_df...")
final_best_prophet_model.fit(train_df[['ds', 'y', 'day_of_week', 'month', 'is_weekend']])
print("Model fitting complete.")

# --- Make predictions with the refitted model on the test set ---
print("\nGenerating predictions on the test set with the final model...")
future_final = final_best_prophet_model.make_future_dataframe(periods=len(test_df), freq='D')
future_final['day_of_week'] = future_final['ds'].dt.dayofweek
future_final['month'] = future_final['ds'].dt.month
future_final['is_weekend'] = future_final['day_of_week'].isin([5, 6]).astype(int)

forecast_final = final_best_prophet_model.predict(future_final)

# Filter forecast for the test period dates
forecast_test_final = forecast_final[forecast_final['ds'].isin(test_df['ds'])]
y_pred_final = forecast_test_final['yhat'].values

print("Prediction complete.")

# --- Calculate and display metrics for the refitted model ---
print("\nCalculating final performance metrics for the tuned model...")
rmse_final = np.sqrt(mean_squared_error(y_true, y_pred_final))
mae_final = mean_absolute_error(y_true, y_pred_final)
mape_final = mean_absolute_percentage_error(y_true, y_pred_final)

print("\n--- Final Tuned Prophet Model Performance ---")
print(f"  RMSE: {rmse_final:.2f}")
print(f"  MAE: {mae_final:.2f}")
print(f"  MAPE: {mape_final:.2f}%")
print("(These metrics should match the best found during tuning)")


fig_forecast_final = final_best_prophet_model.plot(forecast_test_final)
plt.plot(test_df['ds'], y_true, 'k.', label='Actual Test Data')
plt.title('Final Tuned Prophet Forecast vs Actual (Test Set)')
plt.legend()
plt.show()

"""LSTM"""

import itertools
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Define parameter grid for LSTM
param_grid_lstm = {
    'units': [64, 128], # OLD_HP[64,128]
    'batch_size': [32], # OLD_HP[32,64]
    'epochs': [50], # OLD_HP[30,50]
    'learning_rate': [0.001, 0.0005],
    'dropout_rate': [0.0, 0.2],
    'num_layers': [2] # OLD_HP[1,2]
}

best_rmse_lstm_tuned = float('inf')
best_mae_lstm_tuned = float('inf')
best_mape_lstm_tuned = float('inf')
best_params_lstm_tuned = None
best_model_lstm_tuned = None

# Extract keys and values for itertools.product
keys, values = zip(*param_grid_lstm.items())

# Iterate over all combinations
for combo in itertools.product(*values):
    params = dict(zip(keys, combo))
    print(f"\nTesting LSTM with params: {params}")

    # Build LSTM model based on current params
    model_lstm_gs = Sequential()
    for i in range(params['num_layers']):
        return_sequences = (i < params['num_layers'] - 1)
        if i == 0:
            # First layer needs input_shape
            model_lstm_gs.add(LSTM(params['units'], activation='relu',
                                   return_sequences=return_sequences,
                                   input_shape=(SEQ_LEN, N_FEATURES)))
        else:
            model_lstm_gs.add(LSTM(params['units'], activation='relu',
                                   return_sequences=return_sequences))
        if params['dropout_rate'] > 0:
            model_lstm_gs.add(Dropout(params['dropout_rate']))
    model_lstm_gs.add(Dense(1))

    # Compile model
    optimizer = Adam(learning_rate=params['learning_rate'])
    model_lstm_gs.compile(optimizer=optimizer, loss='mse')

    # Train model (silently for tuning loop)
    history = model_lstm_gs.fit(X_train_lstm_hols, y_train_lstm_hols,
                                epochs=params['epochs'],
                                batch_size=params['batch_size'],
                                validation_data=(X_test_lstm_hols, y_test_lstm_hols),
                                verbose=0)

    # Predict on test set (scaled)
    y_pred_scaled_gs = model_lstm_gs.predict(X_test_lstm_hols)

    # Inverse transform predictions
    y_pred_unscaled_gs = scaler_y_only.inverse_transform(y_pred_scaled_gs).flatten()

    # Calculate metrics using unscaled values
    current_rmse = np.sqrt(mean_squared_error(y_true_lstm_hols_unscaled, y_pred_unscaled_gs))
    current_mae = mean_absolute_error(y_true_lstm_hols_unscaled, y_pred_unscaled_gs)
    current_mape = mean_absolute_percentage_error(y_true_lstm_hols_unscaled, y_pred_unscaled_gs)

    print(f"    RMSE: {current_rmse:.2f}, MAE: {current_mae:.2f}, MAPE: {current_mape:.2f}%")

    if current_rmse < best_rmse_lstm_tuned:
        best_rmse_lstm_tuned = current_rmse
        best_mae_lstm_tuned = current_mae
        best_mape_lstm_tuned = current_mape
        best_params_lstm_tuned = params
        best_model_lstm_tuned = model_lstm_gs
        print(f"    >>> New best LSTM model found!")

print("\nLSTM Hyperparameter Tuning Complete.")
print(f"Best LSTM hyperparameters found: {best_params_lstm_tuned}")
print(f"\nMetrics for the Best Tuned LSTM Model:")
print(f"  Best RMSE: {best_rmse_lstm_tuned:.2f}")
print(f"  Corresponding MAE: {best_mae_lstm_tuned:.2f}")
print(f"  Corresponding MAPE: {best_mape_lstm_tuned:.2f}%")

print(f"Using best LSTM parameters found: {best_params_lstm_tuned}")
print(f"Best LSTM Metrics (from tuning loop): RMSE={best_rmse_lstm_tuned:.2f}, MAE={best_mae_lstm_tuned:.2f}, MAPE={best_mape_lstm_tuned:.2f}%")


print("\nGenerating predictions with the final best LSTM model...")
y_pred_scaled_best_lstm = best_model_lstm_tuned.predict(X_test_lstm_hols)

# Inverse transform predictions
y_pred_unscaled_best_lstm = scaler_y_only.inverse_transform(y_pred_scaled_best_lstm).flatten()

print("\nVerifying performance metrics for the best tuned LSTM model...")
rmse_best_lstm_check = np.sqrt(mean_squared_error(y_true_lstm_hols_unscaled, y_pred_unscaled_best_lstm))
mae_best_lstm_check = mean_absolute_error(y_true_lstm_hols_unscaled, y_pred_unscaled_best_lstm)
mape_best_lstm_check = mean_absolute_percentage_error(y_true_lstm_hols_unscaled, y_pred_unscaled_best_lstm)

print(f"  Verified RMSE: {rmse_best_lstm_check:.2f}")
print(f"  Verified MAE: {mae_best_lstm_check:.2f}")
print(f"  Verified MAPE: {mape_best_lstm_check:.2f}%")
print("(These should match the best metrics reported after the tuning loop)")

# --- Optional: Plot forecast vs actual for the final LSTM model ---
print("\nGenerating forecast vs actual plot for the final tuned LSTM model...")
# Get the dates corresponding to the predictions
test_dates_for_best_lstm_eval = daily_df_for_lstm['ds'].iloc[split_idx + SEQ_LEN:]

plt.figure(figsize=(15, 7))
plt.plot(test_dates_for_best_lstm_eval, y_true_lstm_hols_unscaled, marker='.', linestyle='None', label='Actual Units Sold')
plt.plot(test_dates_for_best_lstm_eval, y_pred_unscaled_best_lstm, marker='.', linestyle='None', color='orange', label='Tuned LSTM Forecast')
plt.title('Final Tuned LSTM Forecast vs Actual (Test Set)')
plt.xlabel('Date')
plt.ylabel('Units Sold')
plt.legend()
plt.tight_layout()
plt.show()

print("Comparing Final Performance Metrics Across Models:\n")

# --- Prophet Models ---
print("--- Prophet ---")
try:
    print(f"  Baseline (Regressors):      RMSE={rmse:.2f}, MAE={mae:.2f}, MAPE={mape:.2f}%")
except NameError:
    print("  Baseline (Regressors):      Metrics not found (run the corresponding code).")

try:
    print(f"  Baseline (+ Holidays):      RMSE={rmse_hols:.2f}, MAE={mae_hols:.2f}, MAPE={mape_hols:.2f}%")
except NameError:
    print("  Baseline (+ Holidays):      Metrics not found (run the corresponding code).")

try:
    print(f"  Tuned (+ Holidays + HP):    RMSE={best_rmse_prophet:.2f}, MAE={best_mae_prophet:.2f}, MAPE={best_mape_prophet:.2f}%")
    print(f"    (Best Params: {best_params_prophet})")
except NameError:
    print("  Tuned (+ Holidays + HP):    Metrics not found (run the HP tuning loop).")


# --- LSTM Models ---
print("\n--- LSTM ---")
try:
    print(f"  Baseline (Univariate):      RMSE={rmse_lstm:.2f}, MAE={mae_lstm:.2f}, MAPE={mape_lstm:.2f}%")
except NameError:
    print("  Baseline (Univariate):      Metrics not found (run the corresponding code).")

try:
    print(f"  Baseline (Multi-Feature):   RMSE={rmse_lstm_hols:.2f}, MAE={mae_lstm_hols:.2f}, MAPE={mape_lstm_hols:.2f}%")
except NameError:
    print("  Baseline (Multi-Feature):   Metrics not found (run the corresponding code).")

try:
    print(f"  Tuned (Multi-Feature + HP): RMSE={best_rmse_lstm_tuned:.2f}, MAE={best_mae_lstm_tuned:.2f}, MAPE={best_mape_lstm_tuned:.2f}%")
    print(f"    (Best Params: {best_params_lstm_tuned})")
except NameError:
    print("  Tuned (Multi-Feature + HP): Metrics not found (run the HP tuning loop).")

print("\n============================================================")
print("(Lower RMSE, MAE, MAPE are better)")

